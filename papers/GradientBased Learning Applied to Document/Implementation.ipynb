{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4073af6c-3998-48d1-b569-c5682cddda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5809498-a749-41dc-9a72-b7b3dec867d6",
   "metadata": {},
   "source": [
    "MNIST dataset have images that have size (28,28) therefore we resize them into (32,32). We also Normalize pixels from [0,1] to [-1,1]. We do that so we can get negative gradients. If we had only [0,1] then gradient would always be positive and it would screw with our optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dc39ce-a025-4443-9310-b5df9f9a64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2ac27e-5a8d-40d1-8b2d-a028ef90f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d82b5d-2bdd-4c13-9208-288940a74443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198e6315-ddac-4938-a062-aec99cd3c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fad5cd7-0595-4a9e-9463-d543b8fa3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831b30b0-79d1-499c-9340-52ef84f46a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiar obrazków = torch.Size([64, 1, 32, 32])\n",
      "Rozmiar obrazków = torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataloader)\n",
    "img, label = next(data_iter)\n",
    "print(f'Rozmiar obrazków = {img.shape}')\n",
    "print(f'Rozmiar obrazków = {label.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934fa955-4f67-4410-8ee2-c3b222402c84",
   "metadata": {},
   "source": [
    "For a sake of simplicity i will hardcode the layers sizes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6171bc4-99c9-42e6-b2a0-faa506c4fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.C1 = nn.Conv2d(in_channels = 1,out_channels = 6, kernel_size = (5,5))\n",
    "        self.S2 = nn.AvgPool2d(kernel_size=(2,2),stride=2)\n",
    "        self.C3 = nn.Conv2d(in_channels = 6,out_channels = 16, kernel_size = (5,5))\n",
    "        self.S4 = nn.AvgPool2d(kernel_size = (2,2), stride = 2)\n",
    "        self.L5 = nn.Linear(400,120)\n",
    "        self.L6 = nn.Linear(120,84)\n",
    "        self.Output = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.C1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.S2(x)\n",
    "\n",
    "        x = self.C3(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.S4(x)\n",
    "\n",
    "        x = x.view(-1,400)\n",
    "\n",
    "        x = self.L5(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.L6(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.Output(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abcb773-fd28-453d-bce3-dbdc7c28ff13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6abf61b5-aaa2-4802-bf92-9a981f268a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = LeNet().to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41dc41e7-4b36-4ae0-92d5-e96c40515535",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde56266-4e3e-4184-963c-96ad02f6242c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0 | loss = 0.1079\n",
      "Epoch=1 | loss = 0.0992\n",
      "Epoch=2 | loss = 0.0917\n",
      "Epoch=3 | loss = 0.0854\n",
      "Epoch=4 | loss = 0.0800\n",
      "Epoch=5 | loss = 0.0752\n",
      "Epoch=6 | loss = 0.0710\n",
      "Epoch=7 | loss = 0.0669\n",
      "Epoch=8 | loss = 0.0639\n",
      "Epoch=9 | loss = 0.0608\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for step, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.grad = None\n",
    "\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_function(pred,y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch={epoch} | loss = {avg_loss:.4f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fae8e0f-0e64-410e-a198-169ee66aef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False,\n",
    "                                          transform=transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=64, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ff20fbf-2957-477e-9d9c-672dfa8322c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(loader,model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0) \n",
    "            correct += (predicted == labels).sum().item() \n",
    "    model_eval(test_loader,model)\n",
    "    acc = 100 * correct / total\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Dokładność modelu na zbiorze testowym: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47bb7f1c-5fb2-454c-be36-7b7d6ee01763",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mmodel_eval\u001b[39m\u001b[34m(loader, model)\u001b[39m\n\u001b[32m     12\u001b[39m         total += labels.size(\u001b[32m0\u001b[39m) \n\u001b[32m     13\u001b[39m         correct += (predicted == labels).sum().item() \n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m acc = \u001b[32m100\u001b[39m * correct / total\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDokładność modelu na zbiorze testowym: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mmodel_eval\u001b[39m\u001b[34m(loader, model)\u001b[39m\n\u001b[32m     12\u001b[39m         total += labels.size(\u001b[32m0\u001b[39m) \n\u001b[32m     13\u001b[39m         correct += (predicted == labels).sum().item() \n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m acc = \u001b[32m100\u001b[39m * correct / total\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDokładność modelu na zbiorze testowym: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m)\n",
      "    \u001b[31m[... skipping similar frames: model_eval at line 14 (947 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mmodel_eval\u001b[39m\u001b[34m(loader, model)\u001b[39m\n\u001b[32m     12\u001b[39m         total += labels.size(\u001b[32m0\u001b[39m) \n\u001b[32m     13\u001b[39m         correct += (predicted == labels).sum().item() \n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m acc = \u001b[32m100\u001b[39m * correct / total\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDokładność modelu na zbiorze testowym: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mmodel_eval\u001b[39m\u001b[34m(loader, model)\u001b[39m\n\u001b[32m      4\u001b[39m model.eval()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = _Image_fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[39m, in \u001b[36mNormalize.forward\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) -> Tensor:\n\u001b[32m    270\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\python\\.env\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:928\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(tensor, mean, std, inplace)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m std.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    927\u001b[39m     std = std.view(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_eval(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fa240d6-1ffd-4e5b-8592-3c7f1c96cfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_predictions(model, loader, num_images=10):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "    images = images.cpu()\n",
    "    preds = preds.cpu()\n",
    "    labels = labels.cpu()\n",
    "    rows = 2\n",
    "    cols = num_images // rows\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        img = images[i] / 2 + 0.5 \n",
    "        img = np.transpose(img.numpy(), (1, 2, 0)) \n",
    "        img = img.squeeze() \n",
    "        \n",
    "        ax.imshow(img, cmap='gray')\n",
    "        color = 'green' if preds[i] == labels[i] else 'red'\n",
    "        ax.set_title(f\"P: {preds[i]} | T: {labels[i]}\", color=color)\n",
    "        ax.axis('off') \n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406f2f1-c1a3-4824-bc1b-50a37a242b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
